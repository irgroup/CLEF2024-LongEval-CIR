{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import numpy as np\n",
    "import os\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "from repro_eval.util import arp, arp_scores\n",
    "import pytrec_eval\n",
    "import yaml\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Fuse\n",
    "Fuse the new run with one old run by boosting old (known) documents up and new documents down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_fuse(run_recent, run_old, _lambda=0.5):\n",
    "    qid_ranking_groups = run_old.groupby('qid')\n",
    "    qid_ranking_dict = {qid: list(ranking['docno']) for qid, ranking in qid_ranking_groups}\n",
    "    \n",
    "    def weigh(row):\n",
    "        if not qid_ranking_dict.get(row['qid']):\n",
    "            print(\"Could not find\", row['qid'])\n",
    "            \n",
    "        if row['docno'] in qid_ranking_dict.get(row['qid'], []):\n",
    "            return row['score'] * _lambda ** 2\n",
    "        else:\n",
    "            return row['score'] * (1-_lambda) ** 2              \n",
    "    reranking = run_recent.copy()\n",
    "    \n",
    "    # min max normalization per topic\n",
    "    reranking['score'] = reranking.groupby('qid')['score'].transform(lambda x : x / x.max())\n",
    "    \n",
    "    # weight if in old ranking\n",
    "    reranking['score'] = reranking.progress_apply(weigh, axis=1)\n",
    "    reranking = reranking.sort_values(['qid','score'], ascending=False).groupby('qid').head(10000)\n",
    "    reranking['rank'] = reranking.groupby('qid')['score'].rank(ascending=False).astype(int)\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_t5 = pt.io.read_results('data/results/trec/CIR_BM25_D-t5_T-t5')\n",
    "bm25_t4_extended = pt.io.read_results('data/results/trec/CIR_BM25_D-t4_T-t5_extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 325376/1463631 [00:03<00:11, 100129.99it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# _lambda = 0.5 + 1e-3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m _lambda \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m\n\u001b[0;32m----> 3\u001b[0m bm25_t5_reranked_by_t4 \u001b[38;5;241m=\u001b[39m \u001b[43mtime_fuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbm25_t5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm25_t4_extended\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_lambda\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mtime_fuse\u001b[0;34m(run_recent, run_old, _lambda)\u001b[0m\n\u001b[1;32m     13\u001b[0m reranking[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m reranking\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x : x \u001b[38;5;241m/\u001b[39m x\u001b[38;5;241m.\u001b[39mmax())\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# weight if in old ranking\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m reranking[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mreranking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m reranking \u001b[38;5;241m=\u001b[39m reranking\u001b[38;5;241m.\u001b[39msort_values([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     18\u001b[0m reranking[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m reranking\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrank(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mtime_fuse.<locals>.weigh\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m _lambda \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m_lambda) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/series.py:1095\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     out\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1096\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[1;32m   1097\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# _lambda = 0.5 + 1e-3\n",
    "_lambda = 0.5 + 1e-12\n",
    "bm25_t5_reranked_by_t4 = time_fuse(bm25_t5, bm25_t4_extended, _lambda=_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Kendall's tau:  0.056043715260201694\n"
     ]
    }
   ],
   "source": [
    "pt.io.write_results(bm25_t5_reranked_by_t4, 'bm25_t5_reranked_by_t4', format='trec',run_name='bm25_t5_reranked_by_t4')\n",
    "pt.io.write_results(bm25_t5, 'bm25_t5', format='trec', run_name='bm25_t5')\n",
    "\n",
    "rpd_eval = RpdEvaluator(run_b_orig_path='bm25_t5', run_b_rep_path='bm25_t5_reranked_by_t4')\n",
    "correlations = rpd_eval.ktau_union().get('baseline')\n",
    "correlation_scores = [x for x in list(correlations.values()) if ~np.isnan(x)]\n",
    "print(\"Avg. Kendall's tau: \", sum(correlation_scores) / len(correlation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\"\n",
    "runs_path = \"results/trec\"\n",
    "reranked_path = \"results/fuse_time\"\n",
    "\n",
    "run_new_path = \"CIR_BM25_D-t3_T-t3\"\n",
    "run_old_path = \"CIR_BM25_D-t2_T-t3_extended\"\n",
    "\n",
    "with open(\"data/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 250858/585414 [00:02<00:02, 123910.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116661.91it/s]\n",
      " 43%|████▎     | 250317/585414 [00:02<00:02, 123777.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116324.29it/s]\n",
      " 43%|████▎     | 251829/585414 [00:02<00:02, 124825.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:04<00:00, 117113.72it/s]\n",
      " 43%|████▎     | 250704/585414 [00:02<00:02, 124158.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116875.40it/s]\n",
      " 42%|████▏     | 247741/585414 [00:02<00:02, 122791.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 115944.91it/s]\n",
      " 43%|████▎     | 250453/585414 [00:02<00:02, 124132.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116406.06it/s]\n",
      " 43%|████▎     | 251655/585414 [00:02<00:02, 125090.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:04<00:00, 117095.85it/s]\n",
      " 43%|████▎     | 250979/585414 [00:02<00:02, 124421.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 117038.65it/s]\n",
      " 43%|████▎     | 250989/585414 [00:02<00:02, 123601.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116075.11it/s]\n",
      " 43%|████▎     | 249877/585414 [00:02<00:02, 123762.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 115964.32it/s]\n"
     ]
    }
   ],
   "source": [
    "run_new = pt.io.read_results(os.path.join(base_path, runs_path, run_new_path))\n",
    "run_old = pt.io.read_results(os.path.join(base_path, runs_path, run_old_path))\n",
    "\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)\n",
    "\n",
    "results = {}\n",
    "for l in np.logspace(-3, -12, num=10):  # sweep from 1e-3 to 1e-12\n",
    "    _lambda = 0.5 + l\n",
    "    run_reranked = time_fuse(run_new, run_old, _lambda=_lambda)\n",
    "    results[_lambda] = {}\n",
    "    \n",
    "    # write results\n",
    "    run_name = f'CIR_BM25_D-t3_T-t3_rr-t2-{l}'\n",
    "    run_reranked_path = os.path.join(base_path, reranked_path, run_name)\n",
    "    pt.io.write_results(run_reranked, run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "    # evaluate\n",
    "    rpd_eval = RpdEvaluator(run_b_orig_path=os.path.join(base_path, runs_path, run_new_path), run_b_rep_path=run_reranked_path)\n",
    "    \n",
    "    correlations = rpd_eval.ktau_union().get('baseline')\n",
    "    correlation_scores = [x for x in list(correlations.values()) if ~np.isnan(x)]\n",
    "    avg_tau = sum(correlation_scores) / len(correlation_scores)\n",
    "    results[_lambda][\"tau\"] = avg_tau\n",
    "    \n",
    "    with open(run_reranked_path) as run_reranked:\n",
    "        run = pytrec_eval.parse_run(run_reranked)\n",
    "        scores = evaluator.evaluate(run)\n",
    "        results[_lambda][\"arp\"] = arp_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501 0.07894661726059203 0.4369563935417115\n",
      "0.5001 0.4268032114101738 0.4371686732635674\n",
      "0.50001 0.8274175099065462 0.43726071550788775\n",
      "0.500001 0.9377921482960695 0.43728103787875366\n",
      "0.5000001 0.9530700020867431 0.43728103787875366\n",
      "0.50000001 0.9545358759874004 0.43728103787875366\n",
      "0.500000001 0.9547528153347746 0.43728103787875366\n",
      "0.5000000001 0.9547562635990923 0.43728103787875366\n",
      "0.50000000001 0.9547562635990923 0.43728103787875366\n",
      "0.500000000001 0.9547562635990923 0.43728103787875366\n"
     ]
    }
   ],
   "source": [
    "for l in results.keys():\n",
    "    print(l, results[l][\"tau\"], results[l][\"arp\"][\"bpref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43728103787875366\n"
     ]
    }
   ],
   "source": [
    "# raw ranking\n",
    "with open(os.path.join(base_path, runs_path, run_new_path)) as run_new:\n",
    "    run = pytrec_eval.parse_run(run_new)\n",
    "    scores = evaluator.evaluate(run)\n",
    "    print(arp_scores(scores)[\"bpref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "from ranx import Run, fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_fuse(run_recent, old_runs: list):\n",
    "    qid_ranking_groups = run_recent.groupby('qid')\n",
    "    qid_ranking_dict_recent = {qid: pd.Series(ranking['score'].values, ranking['docno']).to_dict() for qid, ranking in qid_ranking_groups}\n",
    "    \n",
    "    runs = [Run.from_dict(qid_ranking_dict_recent)]\n",
    "    \n",
    "    for run_old in old_runs:\n",
    "        qid_ranking_groups = run_old.groupby('qid')\n",
    "        qid_ranking_dict_old = {qid: pd.Series(ranking['score'].values, ranking['docno']).to_dict() for qid, ranking in qid_ranking_groups}\n",
    "        for qid, ranking in qid_ranking_dict_old.items():\n",
    "            docs_recent = qid_ranking_dict_recent.get(qid).keys()\n",
    "            qid_ranking_dict_old[qid] = {docid: score for docid, score in ranking.items() if docid in docs_recent}\n",
    "        runs.append(Run.from_dict(qid_ranking_dict_old))\n",
    "    \n",
    "    combined_run = fuse(runs = runs, method = \"rrf\")\n",
    "\n",
    "    return combined_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\"\n",
    "runs_path = \"results/trec\"\n",
    "reranked_path = \"results/filter_fuse\"\n",
    "\n",
    "run_new_path = \"CIR_BM25_D-t3_T-t3\"\n",
    "run_old_path = \"CIR_BM25_D-t2_T-t3_extended\"\n",
    "\n",
    "with open(\"data/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_new = pt.io.read_results(os.path.join(base_path, runs_path, run_new_path))\n",
    "\n",
    "old_runs = []\n",
    "for name in os.listdir(os.path.join(base_path, runs_path)):\n",
    "    if \"T-t3\" in name and name.endswith(\"extended\"):\n",
    "        run = pt.io.read_results(os.path.join(base_path, runs_path, name))\n",
    "        old_runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n"
     ]
    }
   ],
   "source": [
    "# find core qids\n",
    "topic_sets = []\n",
    "for i in old_runs:\n",
    "    topic_sets.append(set(i[\"qid\"]))\n",
    "topic_sets.append(set(run_new[\"qid\"]))\n",
    "\n",
    "core = set.intersection(*topic_sets)\n",
    "print(len(core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runs_cleaned = []\n",
    "for run in old_runs:\n",
    "    old_runs_cleaned.append(run[run[\"qid\"].isin(core)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runs = old_runs_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_new_cleaned = run_new[run_new[\"qid\"].isin(core)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reranked = filter_and_fuse(run_new_cleaned, old_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f'CIR_BM25_D-t3_T-t3_rr-ff'\n",
    "run_reranked_path = os.path.join(base_path, reranked_path, run_name)\n",
    "run_reranked.save(run_reranked_path,  kind='trec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Kendall's tau:  0.004242197558995947\n",
      "0.4218068440668467\n"
     ]
    }
   ],
   "source": [
    "rpd_eval = RpdEvaluator(run_b_orig_path=os.path.join(base_path, runs_path, run_new_path), run_b_rep_path=run_reranked_path)\n",
    "\n",
    "correlations = rpd_eval.ktau_union().get('baseline')\n",
    "correlation_scores = [x for x in list(correlations.values()) if ~np.isnan(x)]\n",
    "\n",
    "print(\"Avg. Kendall's tau: \", sum(correlation_scores) / len(correlation_scores))\n",
    "\n",
    "with open(run_reranked_path) as run_reranked:\n",
    "    run = pytrec_eval.parse_run(run_reranked)\n",
    "    scores = evaluator.evaluate(run)\n",
    "    print(arp_scores(scores)[\"bpref\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
