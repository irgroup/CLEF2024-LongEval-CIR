{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import numpy as np\n",
    "import os\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "from repro_eval.util import arp, arp_scores\n",
    "import pytrec_eval\n",
    "import yaml\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Fuse\n",
    "Fuse the new run with one old run by boosting old (known) documents up and new documents down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_fuse(run_recent, run_old, _lambda=0.5):\n",
    "    qid_ranking_groups = run_old.groupby('qid')\n",
    "    qid_ranking_dict = {qid: list(ranking['docno']) for qid, ranking in qid_ranking_groups}\n",
    "    \n",
    "    def weigh(row):\n",
    "        if not qid_ranking_dict.get(row['qid']):\n",
    "            print(\"Could not find\", row['qid'])\n",
    "            \n",
    "        if row['docno'] in qid_ranking_dict.get(row['qid'], []):\n",
    "            return row['score'] * _lambda ** 2\n",
    "        else:\n",
    "            return row['score'] * (1-_lambda) ** 2           \n",
    "    reranking = run_recent.copy()\n",
    "    \n",
    "    # min max normalization per topic\n",
    "    reranking['score'] = reranking.groupby('qid')['score'].transform(lambda x : x / x.max())\n",
    "    \n",
    "    # weight if in old ranking\n",
    "    reranking['score'] = reranking.progress_apply(weigh, axis=1)\n",
    "    reranking = reranking.sort_values(['qid','score'], ascending=False).groupby('qid').head(1000)\n",
    "    reranking['rank'] = reranking.groupby('qid')['score'].rank(ascending=False).astype(int)\n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\"\n",
    "runs_path = \"results/trec\"\n",
    "reranked_path = \"results/fuse_time\"\n",
    "\n",
    "run_new_path = \"CIR_BM25_D-t3_T-t3\"\n",
    "run_old_path = \"CIR_BM25_D-t2_T-t3_extended\"\n",
    "\n",
    "with open(\"data/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 247303/585414 [00:02<00:02, 123534.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 114778.07it/s]\n",
      " 43%|████▎     | 251143/585414 [00:02<00:02, 124120.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 114582.20it/s]\n",
      " 43%|████▎     | 249833/585414 [00:02<00:02, 119381.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 114081.36it/s]\n",
      " 43%|████▎     | 251168/585414 [00:02<00:02, 123765.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 115305.28it/s]\n",
      " 44%|████▍     | 257482/585414 [00:02<00:02, 122168.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 113560.81it/s]\n",
      " 44%|████▎     | 255895/585414 [00:02<00:02, 118387.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 114535.22it/s]\n",
      " 42%|████▏     | 248071/585414 [00:02<00:02, 121581.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 114866.50it/s]\n",
      " 43%|████▎     | 252952/585414 [00:02<00:02, 126103.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:04<00:00, 118141.51it/s]\n",
      " 43%|████▎     | 249526/585414 [00:02<00:02, 124278.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:05<00:00, 116031.93it/s]\n",
      " 43%|████▎     | 253079/585414 [00:02<00:02, 126240.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n",
      "Could not find q012351539607713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585414/585414 [00:04<00:00, 117219.08it/s]\n"
     ]
    }
   ],
   "source": [
    "run_new = pt.io.read_results(os.path.join(base_path, runs_path, run_new_path))\n",
    "run_old = pt.io.read_results(os.path.join(base_path, runs_path, run_old_path))\n",
    "\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)\n",
    "\n",
    "results = {}\n",
    "# for l in np.logspace(-3, -6, num=10):  # sweep from 1e-3 to 1e-12\n",
    "for l in range(1, 11):\n",
    "    _lambda =  l/10\n",
    "    # _lambda = 0.5 + l\n",
    "    run_reranked = time_fuse(run_new, run_old, _lambda=_lambda)\n",
    "    results[_lambda] = {}\n",
    "    \n",
    "    # write results\n",
    "    run_name = f'CIR_BM25_D-t3_T-t3_rr-t2-{l}'\n",
    "    run_reranked_path = os.path.join(base_path, reranked_path, run_name)\n",
    "    pt.io.write_results(run_reranked, run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "    # evaluate\n",
    "    rpd_eval = RpdEvaluator(run_b_orig_path=os.path.join(base_path, runs_path, run_new_path), run_b_rep_path=run_reranked_path)\n",
    "    \n",
    "    correlations = rpd_eval.ktau_union().get('baseline')\n",
    "    correlation_scores = [x for x in list(correlations.values()) if ~np.isnan(x)]\n",
    "    avg_tau = sum(correlation_scores) / len(correlation_scores)\n",
    "    results[_lambda][\"tau\"] = avg_tau\n",
    "    \n",
    "    with open(run_reranked_path) as run_reranked:\n",
    "        run = pytrec_eval.parse_run(run_reranked)\n",
    "        scores = evaluator.evaluate(run)\n",
    "        results[_lambda][\"arp\"] = arp_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0.1 | 0.0061 | 0.1214 | 0.4335 | 0.3139 |\n",
      "| 0.2 | 0.0061 | 0.1214 | 0.4335 | 0.3139 |\n",
      "| 0.3 | 0.0061 | 0.1214 | 0.4335 | 0.3139 |\n",
      "| 0.4 | 0.0059 | 0.1217 | 0.4333 | 0.3153 |\n",
      "| 0.5 | 1.0 | 0.1624 | 0.4373 | 0.3638 |\n",
      "| 0.6 | 0.0134 | 0.1157 | 0.4196 | 0.2841 |\n",
      "| 0.7 | 0.012 | 0.1125 | 0.4194 | 0.2764 |\n",
      "| 0.8 | 0.0122 | 0.1125 | 0.4194 | 0.2763 |\n",
      "| 0.9 | 0.0122 | 0.1125 | 0.4194 | 0.2763 |\n",
      "| 1.0 | 0.0061 | 0.112 | 0.399 | 0.2657 |\n"
     ]
    }
   ],
   "source": [
    "for l in results.keys():\n",
    "    print(\"|\", \" | \".join([\n",
    "        str(l), \n",
    "        str(round(results[l][\"tau\"], 4)), \n",
    "        str(round(results[l][\"arp\"][\"P_10\"], 4)), \n",
    "        str(round(results[l][\"arp\"][\"bpref\"], 4)), \n",
    "        str(round(results[l][\"arp\"][\"ndcg\"], 4))\n",
    "        ]), \"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "from ranx import Run, fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_fuse(run_recent, old_runs: list):\n",
    "    qid_ranking_groups = run_recent.groupby('qid')\n",
    "    qid_ranking_dict_recent = {qid: pd.Series(ranking['score'].values, ranking['docno']).to_dict() for qid, ranking in qid_ranking_groups}\n",
    "    \n",
    "    runs = [Run.from_dict(qid_ranking_dict_recent)]\n",
    "    \n",
    "    for run_old in old_runs:\n",
    "        qid_ranking_groups = run_old.groupby('qid')\n",
    "        qid_ranking_dict_old = {qid: pd.Series(ranking['score'].values, ranking['docno']).to_dict() for qid, ranking in qid_ranking_groups}\n",
    "        for qid, ranking in qid_ranking_dict_old.items():\n",
    "            docs_recent = qid_ranking_dict_recent.get(qid).keys()\n",
    "            qid_ranking_dict_old[qid] = {docid: score for docid, score in ranking.items() if docid in docs_recent}\n",
    "        runs.append(Run.from_dict(qid_ranking_dict_old))\n",
    "    \n",
    "    combined_run = fuse(runs = runs, method = \"rrf\")\n",
    "\n",
    "    return combined_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\"\n",
    "runs_path = \"results/trec\"\n",
    "reranked_path = \"results/filter_fuse\"\n",
    "\n",
    "run_new_path = \"CIR_BM25_D-t3_T-t3\"\n",
    "run_old_path = \"CIR_BM25_D-t2_T-t3_extended\"\n",
    "\n",
    "with open(\"data/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_new = pt.io.read_results(os.path.join(base_path, runs_path, run_new_path))\n",
    "\n",
    "old_runs = []\n",
    "for name in os.listdir(os.path.join(base_path, runs_path)):\n",
    "    if \"T-t3\" in name and name.endswith(\"extended\"):\n",
    "        run = pt.io.read_results(os.path.join(base_path, runs_path, name))\n",
    "        old_runs.append(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n"
     ]
    }
   ],
   "source": [
    "# find core qids\n",
    "topic_sets = []\n",
    "for i in old_runs:\n",
    "    topic_sets.append(set(i[\"qid\"]))\n",
    "topic_sets.append(set(run_new[\"qid\"]))\n",
    "\n",
    "core = set.intersection(*topic_sets)\n",
    "print(len(core))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runs_cleaned = []\n",
    "for run in old_runs:\n",
    "    old_runs_cleaned.append(run[run[\"qid\"].isin(core)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_runs = old_runs_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_new_cleaned = run_new[run_new[\"qid\"].isin(core)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reranked = filter_and_fuse(run_new_cleaned, old_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f'CIR_BM25_D-t3_T-t3_rr-ff'\n",
    "run_reranked_path = os.path.join(base_path, reranked_path, run_name)\n",
    "run_reranked.save(run_reranked_path,  kind='trec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Kendall's tau:  0.004242197558995947\n",
      "0.4218\n",
      "0.1062\n",
      "0.2914\n"
     ]
    }
   ],
   "source": [
    "rpd_eval = RpdEvaluator(run_b_orig_path=os.path.join(base_path, runs_path, run_new_path), run_b_rep_path=run_reranked_path)\n",
    "\n",
    "correlations = rpd_eval.ktau_union().get('baseline')\n",
    "correlation_scores = [x for x in list(correlations.values()) if ~np.isnan(x)]\n",
    "\n",
    "print(\"Avg. Kendall's tau: \", sum(correlation_scores) / len(correlation_scores))\n",
    "\n",
    "with open(run_reranked_path) as run_reranked:\n",
    "    run = pytrec_eval.parse_run(run_reranked)\n",
    "    scores = evaluator.evaluate(run)\n",
    "    print(round(arp_scores(scores)[\"bpref\"], 4))\n",
    "    print(round(arp_scores(scores)[\"P_10\"], 4))\n",
    "    print(round(arp_scores(scores)[\"ndcg\"], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
