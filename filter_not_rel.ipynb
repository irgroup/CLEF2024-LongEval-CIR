{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jueri/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import yaml\n",
    "import os\n",
    "from src.load_index import load_index, load_topics, load_qrels, tag\n",
    "from src.extend_runs import extend_run_full\n",
    "import sqlite3\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "\n",
    "from repro_eval.util import arp, arp_scores\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loaded index with  2049729 documents.\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/LongEval/metadata.yml\", \"r\") as yamlfile:\n",
    "    config = yaml.load(yamlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "results_path = \"data/results/filter_not_rel/\"\n",
    "\n",
    "index = load_index(\"t3\")\n",
    "topics = load_topics(\"t3\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create baseline with 1500 docs per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended baseine for filtering\n",
    "# BM25 = pt.BatchRetrieve(index, wmodel=\"BM25\", verbose=True, num_results=1500)\n",
    "\n",
    "# pt.io.write_results(\n",
    "#     BM25(topics), results_path + f\"/CIR_BM25_D-t3_T-t3-long\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend with docids and qids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loaded run\n",
      ">>> Load doc map\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 23/23.8704 [03:05<00:07,  8.70s/it]/Users/jueri/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "101%|██████████| 24/23.8704 [03:11<-1:59:59,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Load query map\n",
      ">>> Extend run\n"
     ]
    }
   ],
   "source": [
    "# Extend the run\n",
    "new_run = \"CIR_BM25_D-t3_T-t3\"\n",
    "results_path = \"data/results/trec/\"\n",
    "extend_run_full(results_path + new_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend with qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = pd.read_csv(results_path + \"CIR_BM25_D-t3_T_extended.t3\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"data/database.db\")\n",
    "query = \"SELECT * FROM qrel\"\n",
    "qrels = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels[\"key\"] = qrels[\"queryid\"]+qrels[\"docid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmap=qrels[[\"key\", \"relevance\"]].set_index(\"key\").to_dict()[\"relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qrel(row, subcollection):\n",
    "    query_id = row[f\"queryid_{subcollection}\"]\n",
    "    doc_id = row[f\"docid_{subcollection}\"]\n",
    "    if isinstance(query_id, str) and isinstance(doc_id, str):\n",
    "        return qmap.get(row[f\"queryid_{subcollection}\"] + row[f\"docid_{subcollection}\"], None)\n",
    "    else:\n",
    "        return None\n",
    "       \n",
    "for subcollection in [\"t0\", \"t1\", \"t2\", \"t3\"]:\n",
    "    run[f\"qrel_{subcollection}\"] = run.apply(get_qrel, subcollection=subcollection, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adds between 450 to 600 qrels per sub-collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter not rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subcollection in [\"t0\", \"t1\", \"t2\"]:\n",
    "history = [\"t2\", \"t1\", \"t0\"]\n",
    "reranked = run.copy()\n",
    "\n",
    "for subcollection in history:\n",
    "    reranked = reranked[reranked[f\"qrel_{subcollection}\"] != 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked = reranked.sort_values(['queryid','score'], ascending=False).groupby('queryid').head(1000)\n",
    "reranked['rank'] = reranked.groupby('queryid')['score'].rank(ascending=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"CIR_BM25_D-t3_T-t3-filter-notrel-{\"\".join(history)}\"\n",
    "run_reranked_path = os.path.join(results_path, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\"\n",
    "\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| t3 | 0.1798 | 0.7784 | 0.3851 |\n"
     ]
    }
   ],
   "source": [
    "with open(run_reranked_path) as run_reranked:\n",
    "    r = pytrec_eval.parse_run(run_reranked)\n",
    "    scores = evaluator.evaluate(r)\n",
    "    print( \"|\", \n",
    "          \", \".join(history), \"|\",\n",
    "        str(round(arp_scores(scores)[\"P_10\"], 4)), \"|\",\n",
    "        str(round(arp_scores(scores)[\"bpref\"], 4)), \"|\",\n",
    "        str(round(arp_scores(scores)[\"ndcg\"], 4)), \"|\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qrel Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qrel_boost(run, history, _lambda=0.5, mu=2):\n",
    "    reranking = run.copy()\n",
    "    \n",
    "    # min max normalization per topic\n",
    "    reranking['score'] = reranking.groupby('queryid')['score'].transform(lambda x : x / x.max())\n",
    "    \n",
    "    for subcollection in history:\n",
    "        # Relevant\n",
    "        reranking.loc[reranking[f\"qrel_{subcollection}\"] == 1, 'score'] = reranking.loc[reranking[f\"qrel_{subcollection}\"] > 0, 'score'] * _lambda ** 2\n",
    "        reranking.loc[reranking[f\"qrel_{subcollection}\"] > 0, 'score'] = reranking.loc[reranking[f\"qrel_{subcollection}\"] > 0, 'score'] * (_lambda ** 2) * mu\n",
    "        \n",
    "        # All Not Relevant\n",
    "        reranking.loc[(reranking[f\"qrel_{subcollection}\"] == 0) | (reranking[f\"qrel_{subcollection}\"].isna()), 'score'] = reranking.loc[(reranking[f\"qrel_{subcollection}\"] == 0) | (reranking[f\"qrel_{subcollection}\"].isna()), 'score'] *(1-_lambda) ** 2\n",
    "\n",
    "        \n",
    "    reranking = reranking.sort_values(['queryid','score'], ascending=False).groupby('queryid').head(1000)\n",
    "    reranking['rank'] = reranking.groupby('queryid')['score'].rank(ascending=False).astype(int)\n",
    "    \n",
    "    return reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lambda = 0.7\n",
    "history = [\"t2\", \"t1\", \"t0\"]\n",
    "\n",
    "reranked = qrel_boost(run, history, _lambda)\n",
    "\n",
    "run_name = f\"CIR_BM25_D-t3_T3_qrel_boost-{\"\".join(history)}-l{_lambda}\"\n",
    "run_reranked_path = os.path.join(results_path, run_name)\n",
    "\n",
    "pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| t2, t1, t0 | 0.1 | 0.1492 | 0.4246 | 0.3496 |\n",
      "| t2, t1, t0 | 0.2 | 0.1492 | 0.4246 | 0.3496 |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIR_BM25_D-t3_T3_qrel_boost-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(history)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-l\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_lambda\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m run_reranked_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_path, run_name)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreranked\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqueryid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqueryid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_reranked_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(run_reranked_path) \u001b[38;5;28;01mas\u001b[39;00m run_reranked:\n\u001b[1;32m     18\u001b[0m     r \u001b[38;5;241m=\u001b[39m pytrec_eval\u001b[38;5;241m.\u001b[39mparse_run(run_reranked)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pyterrier/io.py:256\u001b[0m, in \u001b[0;36mwrite_results\u001b[0;34m(res, filename, format, append, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# convert generators to results\u001b[39;00m\n\u001b[1;32m    255\u001b[0m res \u001b[38;5;241m=\u001b[39m coerce_dataframe(res)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSUPPORTED_RESULTS_FORMATS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pyterrier/io.py:262\u001b[0m, in \u001b[0;36m_write_results_trec\u001b[0;34m(res, filename, run_name, append)\u001b[0m\n\u001b[1;32m    260\u001b[0m res_copy\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m res_copy\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_name)\n\u001b[0;32m--> 262\u001b[0m \u001b[43mres_copy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mappend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    317\u001b[0m slicer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[1;32m    318\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc[slicer]\n\u001b[0;32m--> 320\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(res\u001b[38;5;241m.\u001b[39m_iter_column_arrays())\n\u001b[1;32m    323\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_get_values_for_csv(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/frame.py:1410\u001b[0m, in \u001b[0;36mDataFrame._get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_values_for_csv\u001b[39m(\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[0;32m-> 1410\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(mgr, axes\u001b[38;5;241m=\u001b[39mmgr\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:466\u001b[0m, in \u001b[0;36mBaseBlockManager.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    461\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m    462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_values_for_csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:780\u001b[0m, in \u001b[0;36mBlock.get_values_for_csv\u001b[0;34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_values_for_csv\u001b[39m(\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, quoting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    778\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m    779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(result)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7839\u001b[0m, in \u001b[0;36mget_values_for_csv\u001b[0;34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[0m\n\u001b[1;32m   7836\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7838\u001b[0m     values[mask] \u001b[38;5;241m=\u001b[39m na_rep\n\u001b[0;32m-> 7839\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m   7842\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatArrayFormatter\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_path = \"data\"\n",
    "history = [\"t3\", \"t2\", \"t1\", \"t0\"]\n",
    "\n",
    "# with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "#     qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "# evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)\n",
    "\n",
    "\n",
    "for _lambda in [0.7]:\n",
    "    reranked = qrel_boost(run, history, _lambda)\n",
    "    \n",
    "    run_name = f\"CIR_BM25_D-t4_T4_qrel_boost-{\"\".join(history)}-l{_lambda}\"\n",
    "    run_reranked_path = os.path.join(results_path, run_name)\n",
    "\n",
    "    pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "    with open(run_reranked_path) as run_reranked:\n",
    "        r = pytrec_eval.parse_run(run_reranked)\n",
    "        scores = evaluator.evaluate(r)\n",
    "        print( \"|\", \n",
    "              \", \".join(history), \"|\",\n",
    "                      str(_lambda), \"|\",\n",
    "            str(round(arp_scores(scores)[\"P_10\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"bpref\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"ndcg\"], 4)), \"|\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| t2, t1 | 0.1 | 0.1513 | 0.4164 | 0.3442 |\n",
      "| t2, t1 | 0.2 | 0.1513 | 0.4164 | 0.3442 |\n",
      "| t2, t1 | 0.30000000000000004 | 0.1513 | 0.4165 | 0.3443 |\n",
      "| t2, t1 | 0.4 | 0.1517 | 0.4185 | 0.3464 |\n",
      "| t2, t1 | 0.5 | 0.1574 | 0.4256 | 0.3598 |\n",
      "| t2, t1 | 0.6 | 0.1828 | 0.4527 | 0.3884 |\n",
      "| t2, t1 | 0.7000000000000001 | 0.1858 | 0.4533 | 0.3909 |\n",
      "| t2, t1 | 0.8 | 0.1858 | 0.4533 | 0.3909 |\n",
      "| t2, t1 | 0.9 | 0.1858 | 0.4533 | 0.3906 |\n"
     ]
    }
   ],
   "source": [
    "base_path = \"data\"\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)\n",
    "\n",
    "history = [\"t2\", \"t1\"]\n",
    "for _lambda in np.arange(0.1, 1, 0.1):\n",
    "    reranked = qrel_boost(run, history, _lambda)\n",
    "    run_name = f\"CIR_BM25_D-t3_T-t3-filter-notrel-{\"\".join(history)}-l{_lambda}\"\n",
    "    run_reranked_path = os.path.join(results_path, run_name)\n",
    "\n",
    "    pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "    with open(run_reranked_path) as run_reranked:\n",
    "        r = pytrec_eval.parse_run(run_reranked)\n",
    "        scores = evaluator.evaluate(r)\n",
    "        print( \"|\", \n",
    "              \", \".join(history), \"|\",\n",
    "                      str(_lambda), \"|\",\n",
    "            str(round(arp_scores(scores)[\"P_10\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"bpref\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"ndcg\"], 4)), \"|\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| t2, t1, t0 | 0.1 | 0.1492 | 0.4119 | 0.3407 |\n",
      "| t2, t1, t0 | 0.2 | 0.1492 | 0.4119 | 0.3407 |\n",
      "| t2, t1, t0 | 0.30000000000000004 | 0.1492 | 0.4122 | 0.3409 |\n",
      "| t2, t1, t0 | 0.4 | 0.1495 | 0.4148 | 0.343 |\n",
      "| t2, t1, t0 | 0.5 | 0.1559 | 0.4219 | 0.3571 |\n",
      "| t2, t1, t0 | 0.6 | 0.1858 | 0.4534 | 0.3901 |\n",
      "| t2, t1, t0 | 0.7000000000000001 | 0.1891 | 0.4542 | 0.3928 |\n",
      "| t2, t1, t0 | 0.8 | 0.1891 | 0.4542 | 0.3928 |\n",
      "| t2, t1, t0 | 0.9 | 0.1891 | 0.4541 | 0.3927 |\n"
     ]
    }
   ],
   "source": [
    "base_path = \"data\"\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)\n",
    "\n",
    "history = [\"t2\", \"t1\", \"t0\"]\n",
    "for _lambda in np.arange(0.1, 1, 0.1):\n",
    "    reranked = qrel_boost(run, history, _lambda)\n",
    "    run_name = f\"CIR_BM25_D-t3_T-t3-filter-notrel-{\"\".join(history)}-l{_lambda}\"\n",
    "    run_reranked_path = os.path.join(results_path, run_name)\n",
    "\n",
    "    pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "    with open(run_reranked_path) as run_reranked:\n",
    "        r = pytrec_eval.parse_run(run_reranked)\n",
    "        scores = evaluator.evaluate(r)\n",
    "        print( \"|\", \n",
    "              \", \".join(history), \"|\",\n",
    "                      str(_lambda), \"|\",\n",
    "            str(round(arp_scores(scores)[\"P_10\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"bpref\"], 4)), \"|\",\n",
    "            str(round(arp_scores(scores)[\"ndcg\"], 4)), \"|\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\"t2\"]\n",
    "_lambda = 1 + 2\n",
    "reranked = direct_boost(run, history, _lambda=_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = f\"CIR_BM25_D-t3_T-t3-rr-rel-{\"\".join(history)}\"\n",
    "run_reranked_path = os.path.join(results_path, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt.io.write_results(reranked[[\"queryid\", \"0\", \"docid\", \"score\", \"rank\", \"run\"]].rename(columns={\"queryid\": \"qid\", \"docid\": \"docno\"}), run_reranked_path, format='trec', run_name=run_name)\n",
    "\n",
    "base_path = \"data\"\n",
    "\n",
    "with open(os.path.join(base_path, config[\"subcollections\"][\"t3\"][\"qrels\"][\"test\"]), \"r\") as f_qrels:\n",
    "    qrels = pytrec_eval.parse_qrel(f_qrels)\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrels, pytrec_eval.supported_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0.7 | t2, t1, t0 | 0.187 | 0.4515 | 0.391 |\n"
     ]
    }
   ],
   "source": [
    "with open(run_reranked_path) as run_reranked:\n",
    "    r = pytrec_eval.parse_run(run_reranked)\n",
    "    scores = evaluator.evaluate(r)\n",
    "    print( \"|\", \n",
    "          str(_lambda), \"|\",\n",
    "          \", \".join(history), \"|\",\n",
    "        str(round(arp_scores(scores)[\"P_10\"], 4)), \"|\",\n",
    "        str(round(arp_scores(scores)[\"bpref\"], 4)), \"|\",\n",
    "        str(round(arp_scores(scores)[\"ndcg\"], 4)), \"|\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
