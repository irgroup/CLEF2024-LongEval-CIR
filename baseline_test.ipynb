{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jueri/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import yaml\n",
    "import os\n",
    "from src.load_index import load_index, load_topics, load_qrels, tag\n",
    "from src.extend_runs import extend_run_full\n",
    "import sqlite3\n",
    "from repro_eval.Evaluator import RpdEvaluator\n",
    "import pytrec_eval\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from argparse import ArgumentParser\n",
    "from repro_eval.util import arp, arp_scores\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:54:42.954 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - OutOfMemoryError: Structure meta reading data file directly from disk\n",
      ">>> Loaded index with  2049729 documents.\n"
     ]
    }
   ],
   "source": [
    "index = load_index(\"t3\")\n",
    "topics = load_topics(\"t3\", \"test\")\n",
    "qrels = load_qrels(\"t3\", \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "pl2 = pt.BatchRetrieve(index, wmodel=\"PL2\")\n",
    "XSqrA_M = pt.BatchRetrieve(index, wmodel=\"XSqrA_M\", verbose=True)\n",
    "DPH = pt.BatchRetrieve(index, wmodel=\"DPH\", verbose=True)\n",
    "rm3_pipe = bm25 >> pt.rewrite.RM3(index) >> bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:   0%|          | 0/6 [05:43<?, ?system/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RelevanceEvaluator.__init__() got an unexpected keyword argument 'judged_docs_only_flag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf_idf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbm25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXSqrA_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDPH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrm3_pipe\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP_10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbpref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mndcg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_rel_ret\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecip_rank\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pyterrier/pipelines.py:471\u001b[0m, in \u001b[0;36mExperiment\u001b[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     save_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.res.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[0;32m--> 471\u001b[0m time, evalMeasuresDict \u001b[38;5;241m=\u001b[39m \u001b[43m_run_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackfill_qids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_topic_qids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     evalDictsPerQ\u001b[38;5;241m.\u001b[39mappend(evalMeasuresDict)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/pyterrier/pipelines.py:206\u001b[0m, in \u001b[0;36m_run_and_evaluate\u001b[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m topics, but no results received from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(topics), \u001b[38;5;28mstr\u001b[39m(system)) )\n\u001b[1;32m    205\u001b[0m     evalMeasuresDict \u001b[38;5;241m=\u001b[39m _ir_measures_to_dict(\n\u001b[0;32m--> 206\u001b[0m         \u001b[43mir_measures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_irmeasures_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m    207\u001b[0m         metrics,\n\u001b[1;32m    208\u001b[0m         rev_mapping,\n\u001b[1;32m    209\u001b[0m         num_q,\n\u001b[1;32m    210\u001b[0m         perquery,\n\u001b[1;32m    211\u001b[0m         backfill_qids)\n\u001b[1;32m    212\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m#transformer, evaluate queries in batches\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/base.py:70\u001b[0m, in \u001b[0;36mProvider.iter_calc\u001b[0;34m(self, measures, qrels, run)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miter_calc\u001b[39m(\u001b[38;5;28mself\u001b[39m, measures, qrels, run):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovider \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not available\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNAME)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/base.py:78\u001b[0m, in \u001b[0;36mProvider._iter_calc\u001b[0;34m(self, measures, qrels, run)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_calc\u001b[39m(\u001b[38;5;28mself\u001b[39m, measures, qrels, run):\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miter_calc(run)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/fallback_provider.py:33\u001b[0m, in \u001b[0;36mFallbackProvider._evaluator\u001b[0;34m(self, measures, qrels)\u001b[0m\n\u001b[1;32m     31\u001b[0m qrels_teed \u001b[38;5;241m=\u001b[39m QrelsConverter(qrels)\u001b[38;5;241m.\u001b[39mtee(\u001b[38;5;28mlen\u001b[39m(provider_measure_pairs))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (provider, provider_measures), qrels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(provider_measure_pairs, qrels_teed):\n\u001b[0;32m---> 33\u001b[0m     evaluators\u001b[38;5;241m.\u001b[39mappend(\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprovider_measures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqrels\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evaluators) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evaluators[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# skip the overhead of FallbackEvaluator if there's only one\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/base.py:53\u001b[0m, in \u001b[0;36mProvider.evaluator\u001b[0;34m(self, measures, qrels)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluator\u001b[39m(\u001b[38;5;28mself\u001b[39m, measures, qrels) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Evaluator:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m---> 53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprovider not available\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/pytrec_eval_provider.py:66\u001b[0m, in \u001b[0;36mPytrecEvalProvider._evaluator\u001b[0;34m(self, measures, qrels)\u001b[0m\n\u001b[1;32m     62\u001b[0m qrels \u001b[38;5;241m=\u001b[39m ir_measures\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mQrelsConverter(qrels)\u001b[38;5;241m.\u001b[39mas_dict_of_dict()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Depending on the measure params, we may need multiple invocations of pytrec_eval\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# (e.g., with different rel_level, since it only supports running with 1 rel_level at a time)\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m invokers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_invokers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PytrecEvalEvaluator(measures, invokers, qrels)\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/pytrec_eval_provider.py:182\u001b[0m, in \u001b[0;36mPytrecEvalProvider._build_invokers\u001b[0;34m(self, measures, qrels)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gains \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# Map the gains\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         these_qrels \u001b[38;5;241m=\u001b[39m {qid: {did: gains\u001b[38;5;241m.\u001b[39mget(score, score) \u001b[38;5;28;01mfor\u001b[39;00m did, score \u001b[38;5;129;01min\u001b[39;00m vals\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m qid, vals \u001b[38;5;129;01min\u001b[39;00m these_qrels\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 182\u001b[0m     invokers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mPytrecEvalInvoker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytrec_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthese_qrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasure_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudged_only\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m invokers\n",
      "File \u001b[0;32m~/dev/CLEF2024-LongEval-CIR/.venv/lib/python3.12/site-packages/ir_measures/providers/pytrec_eval_provider.py:208\u001b[0m, in \u001b[0;36mPytrecEvalInvoker.__init__\u001b[0;34m(self, pte, qrels, measure_map, rel_level, judged_only)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pte, qrels, measure_map, rel_level, judged_only):\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;241m=\u001b[39m \u001b[43mpte\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRelevanceEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmeasure_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjudged_docs_only_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjudged_only\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasure_map \u001b[38;5;241m=\u001b[39m measure_map\n",
      "\u001b[0;31mTypeError\u001b[0m: RelevanceEvaluator.__init__() got an unexpected keyword argument 'judged_docs_only_flag'"
     ]
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [tf_idf, bm25, pl2, XSqrA_M, DPH, rm3_pipe],\n",
    "    topics,\n",
    "    qrels,\n",
    "    eval_metrics=[\"P_10\", \"bpref\", \"ndcg\", \"num_rel_ret\", \"map\", \"recip_rank\"],\n",
    "    baseline=0,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
